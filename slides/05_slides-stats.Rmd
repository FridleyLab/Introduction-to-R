---
title: "Lea.orange[R]ning about Statistics -YEAH!!!"
subtitle: "STATISTICAL TESTS! "
author: 
  - Zachary Thompson 
institute: "Moffitt Cancer Center"
date: '`r strftime(Sys.time(), "%B %d, %Y")`'
output:
  xaringan::moon_reader:
    lib_dir: libs
    chakra: libs/remark-0.14.0.min.js
    css: 
      - css/moffitt-xaringan.css
      - css/moffitt-xaringan-extra.css
      - css/tachyons.moffitt.css
    seal: false
    nature:
      titleSlideClass: ["bottom", "left"]
      slideNumberFormat: "%current%"
      highlightStyle: atom-one-light
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: true
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=9, fig.height=3.5, fig.retina=3,
  out.width = "100%",
  cache = FALSE,
  echo = TRUE,
  message = FALSE, 
  warning = FALSE, 
  hiline = TRUE,
   comment = NA 
)
options(width = 70)

#Load data...
  #load(file = "Z:/Projects/Fridley_Brooke/2813_R_Programming_Course_2020/data/alldata.RData")
  #load(file = "Z:/Projects/Fridley_Brooke/2813_R_Programming_Course_2020/data/Rclassdata.RData")
  
  #library(here)
  library(easystats)
  library(tidyverse)
  library(kableExtra)
  library(ggplot2)
  library(janitor)
  library(gridExtra)
  library(broom)
   
   #Rclassdata %>% filter(acronym %in% c("KIRC","HNSC")) -> tcga

   
#MERGE and making smoking variable 
clinical <- read.csv(file = "F:\\myGitRepo\\Introduction-to-R\\data\\tcga-clinical.csv", header = TRUE)
geneexp <- read.csv(file = "F:\\myGitRepo\\Introduction-to-R\\data\\tcga-gene-exp.csv", header = TRUE)
# 
# intersect(names(clinical), names(geneexp))
# 
# dim(clinical)
# dim(geneexp)
#  
tcga <- left_join(clinical, geneexp, by = "bcr_patient_barcode")
#dim(tcga)



tcga <- tcga %>% mutate(
  smoking = tobacco_smoking_history,
  smoking = case_when(
    tobacco_smoking_history %in% c(
      "Current reformed smoker for < or = 15 years",
      "Current reformed smoker for > 15 years",
      "Current Reformed Smoker, Duration Not Specified"
    ) ~ "Former",
    tobacco_smoking_history %in% c("Current smoker") ~ "Current",
    tobacco_smoking_history %in% c("Lifelong Non-smoker") ~ "Never",
    is.na(tobacco_smoking_history) ~ NA_character_
  )
)

#table(tcga$smoking, useNA = "always")


```

name: title
class: left bottom hide-count

<!-- Slide Extras -->

```{r xaringan-extras, echo=FALSE, results="asis"}
# remotes::install_github("gadenbuie/xaringanExtra")
xaringanExtra::use_xaringan_extra(c(
  "tile_view"
  # "editable",
  # "animate",
  # "panelset"
))
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```


<!-- Title Slide -->
<!-- <div class="talk-logo"></div> -->

.talk-meta[
.talk-title[
# `r rmarkdown::metadata$title`

`r rmarkdown::metadata$subtitle`
]

.talk-author[
`r paste(rmarkdown::metadata$author, collapse = " &middot; ")`<br>
.moffitt-gray[`r paste(rmarkdown::metadata$institute, collapse = ", ")`]
]

.talk-date.moffitt-gray[
`r knitr::knit(text = rmarkdown::metadata$date)`
]
]


```{css echo=FALSE}
/* Define title slide image or logo here */
.talk-logo {
  width: 400px;
  height: 750px;
  position: absolute;
  top: 6%;
  right: 7%;
  /* background-image: url('img/r4ds-cover.png'); */
  background-size: contain;
  background-repeat: no-repeat;
  background-position: contain;
}
```

<!-- Moffitt Logo and Slide Border ----

All slides except "title" and "inverse" slides
have the Moffitt Color Bar and logo.

Additional classes are provided to disable both:

- `class: no-logo` hides the logo
- `class: no-border` hides the border

or to force either to be shown

- `class: moffitt-slide-logo` shows the logo
- `class: moffitt-slide-border` shows the border
-->

---

## What you will learn to run
 
  
- Review of tables with janitor package
  
- Chi square and Fisher’s test

- Correlations

- Two-sample tests (t-test, wilcoxon test)

- Simple linear regression

---

## Review of tables
 

```{r comment=NA}

janitor::tabyl(tcga, radiation_therapy, vital_status )
   
```
 
 
---

## Review of tables
 

```{r comment=NA}

janitor::tabyl(tcga, radiation_therapy, vital_status, 
               show_na = FALSE )

```

---

## Review of tables
```{r comment=NA}

tcga %>% 
  tabyl(smoking, gender, show_na = FALSE )
```


---

## Review of tables
```{r comment=NA}

tcga %>% 
  tabyl(smoking, gender, show_na = FALSE ) %>% 
  adorn_totals(where = c("row","col"))
```

---

## Review of tables
```{r comment=NA}


tcga %>% 
  tabyl(smoking, gender, show_na = FALSE ) %>% 
  adorn_totals(where = c("row","col")) %>% 
  adorn_percentages(denominator = "col") 
```

---

## Review of tables
```{r comment=NA}

tcga %>% 
  tabyl(smoking, gender, show_na = FALSE ) %>% 
  adorn_totals(where = c("row","col")) %>% 
  adorn_percentages(denominator = "col") %>% 
  adorn_pct_formatting(digits = 0)  

```

---

## Review of tables
```{r comment=NA}

tcga %>% 
  tabyl(smoking, gender, show_na = FALSE ) %>% 
  adorn_totals(where = c("row","col")) %>% 
  adorn_percentages(denominator = "col") %>% 
  adorn_pct_formatting(digits = 0) %>% 
  adorn_ns(position = "front") 
 
```

 
 
---


# Pearson’s chi-squared test
 
The chi squared test is a non-parametric test that can be applied to contingency tables with various dimensions. The name of the test originates from the chi-squared distribution, which is the distribution for the squares of independent standard normal variables. This is the distribution of the test statistic of the chi squared test, which is defined by the sum of chi-square values for all cells arising from the difference between a cell’s observed value and the expected value, normalized by the expected value.
 
$\chi ^{2}$ = $\sum_{ij}$ $\frac{(O_{ij} - E_{ij})^{2}}{E_{ij}}$ 


*   $\chi ^{2}$ = chi square statistic
*   $O_{ij}$ = observed value
*   $E_{ij}$ = expected value


---
## Pearson’s chi-squared test
 
The null hypothesis of the Chi-Square test is that no relationship exists between the categorical variables in the population; they are independent.

 
```{r chisqtest, echo=FALSE ,  include=TRUE}
 tcga %>% 
  tabyl(smoking, gender, show_na = FALSE ) %>% 
  adorn_totals(where = c("row","col")) %>% 
  adorn_percentages(denominator = "col") %>% 
  adorn_pct_formatting(digits = 0)   %>% 
  adorn_ns(position = "front") 
 

 
```
 


---

## Pearson’s chi-squared test
 
The null hypothesis of the Chi-Square test is that no relationship exists between the categorical variables in the population; they are independent.

 

```{r chisqtest1, eval=TRUE,  include=TRUE}
 
tcga %>% tabyl( smoking, gender , show_na = FALSE ) %>%
  chisq.test()

```
 
The p-value is very low so we reject the null hyposthesis that there is no association between the variables. 

---

## Pearson’s chi-squared test
 
  More women are never smokers and more men are current smokers. 
 
.panelset[
.panel[.panel-name[R Code]

```{r geombar, echo = TRUE, fig.show = "hide"}
ggplot(tcga %>% filter(!is.na(smoking)),
       aes(x = gender, fill = smoking )) +  
  geom_bar(position = "fill") +
  labs(y = "proportion")

```
]

.panel[.panel-name[Plot]

```{r ref.label = "geombar", echo = FALSE}
```
]
]
 




 
---



# Fisher’s exact test
 
Fisher's exact test is practically applied only in analysis of small samples but actually it is valid for all sample sizes. While the chi-squared test relies on an approximation, Fisher's exact test is one of exact tests. Especially when more than 20% of cells have expected frequencies < 5, we need to use Fisher's exact test because applying approximation method is inadequate. Fisher's exact test assesses the null hypothesis of independence applying hypergeometric distribution of the numbers in the cells of the table. Many packages provide the results of Fisher's exact test for 2 × 2 contingency tables 
 
---
 

##  Fisher’s exact test
 

```{r comment=NA}
 tcga %>% 
  tabyl( gender, vital_status , show_na = FALSE ) %>% 
  adorn_totals(where = c("row","col")) %>% 
  adorn_percentages(denominator = "col") %>% 
  adorn_pct_formatting(digits = 0) %>% 
  adorn_ns(position = "front") 

```


---


##  Fisher’s exact test
 
  Since the p-value is 0.1285 we fail to reject the null hyposthesis. 

```{r comment=NA}
tcga  %>% tabyl( gender, vital_status , show_na = FALSE ) %>% 
  fisher.test()

```
 
---
 
## Fisher’s exact test: Bar graph
  

```{r geombar2, echo = TRUE }
ggplot(tcga %>% filter(!is.na(vital_status)), 
       aes(x = gender, fill = vital_status )) +  
       geom_bar(position = "fill") + labs(y = "proportion")

```
 


---
 
# Correlation 
 
A correlation coefficient is a numerical measure of some type of correlation, meaning a statistical relationship between two variables.  

Several types of correlation coefficient exist, each with their own definition and own range of usability and characteristics. They all assume values in the range from −1 to +1, where ±1 indicates the strongest possible agreement and 0 no agreement.

 Pearson
 
 Spearman
 
---
 
## Pearson Correlation 

 The .bg-orange.white[Pearson product-moment correlation coefficient], also known as r or Pearson's r, is a measure of the strength and direction of the linear relationship between two variables that is defined as the covariance of the variables divided by the product of their standard deviations.  Pearson's r is the best-known and most commonly used type of correlation coefficient. A relationship is linear when a change in one variable is associated with a proportional change in the other variable.
 
$r_{xy}$ = $\frac{ \sum_{i = 1}^{n}  (x_{i}-  \overline{x} )(y_{i}- \overline{y})}{\sqrt(\sum_{i = 1}^{n}  (x_{i}-  \overline{x} )^{2})\sqrt(\sum_{i = 1}^{n}  (y_{i}-  \overline{y} )^{2})}$ 

*   n is the sample size
*   $x_{i}$ and $y_{i}$  are the individual sample points indexed with i
*   $\overline{x} = \frac{1}{n}\sum_{i = 1}^{n} x_{i}$ is the smaple mean of x (similarly y)



---
 
## Pearson Correlation 
 

```{r  comment=NA}

 
r1 <- tcga %>% correlation::cor_test("DUOXA1_exp", 
                                          "DUOX1_exp", 
                                          method = c("pearson") ) 
 
r2 <- tcga %>% correlation::cor_test("BUB1_exp",
                                          "C10orf32_exp",
                                          method = c("pearson") ) 
 
r3 <- tcga %>% correlation::cor_test("BRAF_exp", 
                                          "DTL_exp", 
                                          method = c("pearson") )
 
```

---
 
## Pearson Correlation 
 

```{r comment=NA}
 knitr::kable(bind_rows(r1,r2,r3 ), format = 'html', digits = 3) %>%
  kable_styling(font_size = 12)

```




---

## Pearson Correlation Scatter Plot

.panelset[
.panel[.panel-name[R Code]

```{r geom, echo = TRUE, fig.show = "hide"}
ggplot(tcga) + 
  aes(DUOXA1_exp, DUOX1_exp) + 
  geom_point() + 
  annotate(geom = "text", x = 10, y = 25000, 
           label = paste("r = ", round(r1$r, 2), sep = ""),
           color = "red")

```
]

.panel[.panel-name[Plot]

```{r ref.label = "geom", echo = FALSE}
```
]
]
 




---

## Pearson Correlation Scatter Plot
  
.panelset[
.panel[.panel-name[R Code]

```{r geom2, echo = TRUE, fig.show = "hide"}

ggplot(tcga) + 
  aes(BUB1_exp, C10orf32_exp) + 
  geom_point() + 
  annotate(geom = "text", x = 1000, y = 4000, 
           label = paste("r = ", round(r2$r, 2), sep = ""),
           color = "red")
 

```
]

.panel[.panel-name[Plot]

```{r ref.label = "geom2", echo = FALSE}
```
]
]

 

---

## Pearson Correlation Scatter Plot
  
.panelset[
.panel[.panel-name[R Code]

```{r geom3, echo = TRUE, fig.show = "hide"}
ggplot(tcga) + 
  aes(BRAF_exp, DTL_exp) + 
  geom_point() + 
  annotate(geom = "text", x = 0, y = 1100, 
           label = paste("r = ", round(r3$r, 2), sep = ""),  
           color = "red")
 

 

```
]

.panel[.panel-name[Plot]

```{r ref.label = "geom3", echo = FALSE}
```
]
]

 


```{r  comment=NA}


```
 




---

## Correllation Matrix 
 

```{r comment=NA}
tcga %>% 
  select(DUOXA1_exp, DUOX1_exp, BUB1_exp, BRAF_exp, DTL_exp ) %>%
  cor() %>% round(.,2)

```


---


## Spearman Correlation 

The Spearman correlation evaluates the monotonic relationship between two continuous or ordinal variables. It is a nonparametric measure of rank correlation (statistical dependence between the rankings of two variables). In a monotonic relationship, the variables tend to change together, but not necessarily at a constant rate. The Spearman correlation coefficient is based on the ranked values for each variable rather than the raw data.
 


---



## Spearman Correlation example of monotonic relationship


 
```{r echo=FALSE, comment=NA}
 

x <- seq(10,20,.25)
y <- (x-15)^3 + 100
pdata <-  data.frame(x,y)
 
ggplot(pdata, aes(x,y)) + geom_point()  

```


---


 

## Spearman Correlation 
 

```{r  comment=NA}

 
r1 <- tcga %>% correlation::cor_test("DUOXA1_exp", 
                                          "DUOX1_exp", 
                                          method = c("spearman") ) 
 
r2 <- tcga %>% correlation::cor_test("BUB1_exp",
                                          "C10orf32_exp",
                                          method = c("spearman") ) 
 
r3 <- tcga %>% correlation::cor_test("BRAF_exp", 
                                          "DTL_exp", 
                                          method = c("spearman") )
 
```

---
 
## Spearman Correlation 
 

```{r comment=NA}
 knitr::kable(bind_rows(r1, r2, r3), format = 'html', digits = 3) %>%
  kable_styling(font_size = 12)

```


 
---

# Two sample tests


- Mann Whitney U Test (Wilcoxon Rank Sum Test) 

- T - test

---

## Mann Whitney U Test (Wilcoxon Rank Sum Test) 

 
A popular non-parametric test to compare outcomes between two independent groups is the Mann Whitney U test. The Mann Whitney U test, sometimes called the Mann Whitney Wilcoxon Test or the Wilcoxon Rank Sum Test, is used to test whether two samples are likely to derive from the same population (i.e., that the two populations have the same shape). 

It can also be used on related samples or matched samples to assess whether their population mean ranks differ (i.e. it is a paired difference test). It can be used as an alternative to the paired Student's t-test when the distribution of the difference between two samples' means cannot be assumed to be normally distributed.   



---

## Wilcoxon test: Histograms
  
.panelset[

.panel[.panel-name[Plot]

```{r ref.label = "wilcoxonhists", echo = FALSE}
```
]

.panel[.panel-name[R Code]

```{r wilcoxonhists, echo = TRUE, fig.show = "hide"}
mplot <- ggplot(tcga %>% filter(gender == "MALE"), 
                aes(x = BUB1_exp )) +
  geom_histogram(  colour = "black", position = "dodge") +
  ggtitle("Males") 

wplot <- ggplot(tcga  %>% filter(gender == "FEMALE"), 
                aes(x = BUB1_exp)) +
  geom_histogram(  colour= "black", position = "dodge")  +
  ggtitle("Females") 
  
grid.arrange(mplot,wplot, ncol=2) 
 

```
]
]



---
 
## Wilcoxon test visulize boxplots gender
  
.panelset[
.panel[.panel-name[R Code]


```{r wilcoxonboxplots, echo = TRUE, fig.show = "hide"}
  
ggplot(tcga , aes(gender, BUB1_exp, fill = gender))  +
  geom_boxplot() +
  scale_fill_manual( values = c("yellow", "blue")) + 
  theme(legend.position = "none") +
  labs(title = "BUB1 expression" , x = "Gender", y = "expression")  

```
]

.panel[.panel-name[Plot]

```{r ref.label = "wilcoxonboxplots", echo = FALSE}
```
]
]




---


## Wilcoxon test gender
```{r comment=NA}
 
 wilcox.test(BUB1_exp ~ gender, data = tcga,
                   alternative = c("two.sided"))
 
 
```

The p-value is very low so we reject the null hypostheis of no difference (0 location shift). 



---

## T-test
 
A t-test is a method used to determine if there 
is a significant difference between the means 
of two groups based on a sample of data.

The test relies on a set of assumptions for it
to be interpreted properly and with validity.
Among these assumptions, the data must be randomly
sampled from the population of interest and 
that the data variables follow a normal
distribution.


---

## T-test assumptions

1. The data are continuous (not discrete).

2. The data follow the normal probability distribution.

3. The variances of the two populations are equal. (If not, the Aspin-Welch Unequal-Variance test is used.)

4. The two samples are independent. There is no relationship between the individuals in one sample as compared to the other (as there is in the paired t-test). 

5. Both samples are simple random samples from their respective populations. Each individual in the population has an equal probability of being selected in the sample.
 


---

## T-test formula

Test Statistic (equal variances):

 
$T  = \frac{\overline{x}_{1} - \overline{x}_{2}}{S_{p}\sqrt(1/N_{1} + 1/N_{2})}$ 

where:
$S^{2}_{p}$ = $\frac{(N_{1}-1)s^{2}_{1} + (N_{1}-1)s^{2}_{1}}{N_{1}+N_{2}-2}$

 

---
 
## T-test visulize boxplots

.panelset[
.panel[.panel-name[R Code]

```{r t2boxplots, echo = TRUE, fig.show = "hide"}
  
ggplot(tcga , aes(gender, PTEN_exp, fill = gender))  +
  geom_boxplot() +
  scale_fill_manual( values = c("yellow", "blue")) + 
  theme(legend.position = "none") +
  labs(title = "PTEN expression" , x = "Gender", y = "expression")  

```
]

.panel[.panel-name[Plot]

```{r ref.label = "t2boxplots", echo = FALSE}
```
]
]



 
---
 
## T-test Visualize data Histograms
  
.panelset[
.panel[.panel-name[R Code]


```{r t2hist, echo = TRUE, fig.show = "hide"}
  ggplot(tcga, aes(x=PTEN_exp, fill=gender)) +
  scale_fill_manual( values = c("red", "blue")) + 
  geom_histogram( alpha=0.6, position="identity")
 
```
]

.panel[.panel-name[Plot]

```{r ref.label = "t2hist", echo = FALSE}
```
]
]




---


## T-test R call

```{r comment=NA}


t.test( tcga$PTEN_exp ~ tcga$gender, 
        alternative = c("two.sided"))
 
```



---

## Simple Linear Regression
 
 A linear regression is a statistical model that analyzes the
 relationship between a response variable (often called y) and 
 one or more variables (often called predictor or
 explanatory variables). Simple linear regression is the case when 
 there is only one predictor variable. 



---

## Simple Linear Regression Assumptions
 
- Linearity: The relationship between X and the mean of Y is linear.

- Homoscedasticity: The variance of residual is the same for any value of X.

- Independence: Observations are independent of each other.

- Normality: For any fixed value of X, Y is normally distributed


---
 

## Simple Linear Regression Examples
 
 Examples: 
  
 Tempature conversion: $F = \frac{9}{5} C + 32$ 

 In general: $Y$ = $\beta_0$ + $\beta_1$ X
 
 where $\beta_0$ is the intercept, and $\beta_1$ is the regression coefficient for the predictor.

---

## Simple Linear Regression Scatterplot
 
```{r echo=FALSE, comment=NA}
 
ggplot(tcga) + 
  aes(DUOXA1_exp, DUOX1_exp ) + 
  geom_point() + 
  annotate(geom = "text", x = 10, y = 25000, 
           label = paste("r = ", round(r1$r,2), sep = ""),
           color = "red")
```

---

#### Base R output 

mod <- lm(DUOX1_exp ~  DUOXA1_exp, data = tcga)
print(summary(mod))

 ```{r echo=FALSE, comment=NA}

mod <- lm(DUOX1_exp ~  DUOXA1_exp, data = tcga)

print(summary(mod))

```


---

#### Broom output 


```{r  comment=NA}

mod <- lm(DUOX1_exp ~  DUOXA1_exp, data = tcga)

tidy(mod)

```
 
 

---
 
#### Kable and Broom output 

```{r comment=NA}
 knitr::kable(tidy(mod), format = 'html', digits = 3) %>%
  kable_styling(font_size = 22)

``` 
 
---

## Simple Linear Regression 
```{r echo=FALSE, comment=NA}
 
ggplot(tcga, aes(DUOXA1_exp, DUOX1_exp )) + 
  geom_point() + 
  annotate(geom = "text", x = 10, y = 25000, 
           label = paste("r = ", round(r1$r,2), sep = ""),
           color = "red") + 
   geom_smooth(method = 'lm')

```

---

## Simple Linear Regression 
 
 The regression coefficient (slope of the line) is 3.03 which means that for every unit increase
 in DUOXA1 the DUOX1 gene expression is increased by 3. 
 
 $DUOX1$ = $84.9$ + $3.03DUOXA1$
 
 ```{r echo=FALSE, comment=NA}
 
 knitr::kable(tidy(mod), format = 'html', digits = 3) %>%   kable_styling(font_size = 22)
```

---

## Thank you! 
  
  - The end

